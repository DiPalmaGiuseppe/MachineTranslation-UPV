{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR baseline experiment using Whisper and Covost2 (Spanish-English setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to learn how to use the Open AI pre-trained model [Whisper](https://openai.com/index/whisper/) for ASR on the [Covost2](https://huggingface.co/datasets/facebook/covost2) speech translation corpus (using the Spanish-English setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some OpenAI source whisper libraries and additional ones (e.g. for computing Word Error Rate, WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josanna/.local/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from whisper.normalizers.basic import BasicTextNormalizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import jiwer\n",
    "\n",
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Covost2 dataset (Spanish-English setup) from Hugging Face. Previously, audio data in the source language (version 4) must be downloaded from [Common Voice](https://commonvoice.mozilla.org/en/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'file', 'audio', 'sentence', 'translation', 'id'],\n",
      "        num_rows: 79015\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['client_id', 'file', 'audio', 'sentence', 'translation', 'id'],\n",
      "        num_rows: 13221\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'file', 'audio', 'sentence', 'translation', 'id'],\n",
      "        num_rows: 13221\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"facebook/covost2\", 'es_en', data_dir=\"/home/josanna/josanna/doc/ta/lab/covost2\")\n",
    "\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the features of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': Value(dtype='string', id=None),\n",
       " 'file': Value(dtype='string', id=None),\n",
       " 'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n",
       " 'sentence': Value(dtype='string', id=None),\n",
       " 'translation': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742144.mp3',\n",
       " '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742146.mp3',\n",
       " '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742323.mp3',\n",
       " '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742324.mp3',\n",
       " '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742325.mp3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][:5][\"file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742144.mp3',\n",
       "  'array': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'sampling_rate': 16000},\n",
       " {'path': '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742146.mp3',\n",
       "  'array': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'sampling_rate': 16000},\n",
       " {'path': '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742323.mp3',\n",
       "  'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         -3.60844243e-09, -2.13593054e-09, -1.02855546e-08]),\n",
       "  'sampling_rate': 16000},\n",
       " {'path': '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742324.mp3',\n",
       "  'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         -8.43218004e-07, -5.10772225e-07, -2.45845513e-07]),\n",
       "  'sampling_rate': 16000},\n",
       " {'path': '/home/josanna/josanna/doc/ta/lab/covost2/clips/common_voice_es_19742325.mp3',\n",
       "  'array': array([-2.27373675e-13, -5.45696821e-12, -5.91171556e-12, ...,\n",
       "          1.77635684e-15, -3.59712260e-14, -5.81756865e-14]),\n",
       "  'sampling_rate': 16000}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][:5][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 5 Spanish references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tras su lanzamiento ha recibido positivas reseñas por parte de la crítica especializada.',\n",
       " 'Las hojas se secan a la sombra, en un lugar aireado.',\n",
       " 'Por este motivo no pudo integrar la selección de su país.',\n",
       " 'Es profundo y navegable sin problemas a medio canal.',\n",
       " '\"Pretendía recoger la herencia de revistas como \"\"La Codorniz\"\" o \"\"El hermano lobo\"\".\"']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][:5][\"sentence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 5 english translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After its release, it has received positive feedback from expert critics.',\n",
       " 'Leaves are dried in the shade, in a ventilated place.',\n",
       " 'For this reason, he could not be part of his country’s national team.',\n",
       " 'The middle of the channel is deep and you can navigate without any problem.',\n",
       " 'It intended to preserve the heritage of magazines such as “La Codorniz” or “El hermano lobo.”']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][:5][\"translation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick up the first 1000 audio samples from the training split to be automatically transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=raw_datasets[\"validation\"][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe all the audio data using the Whisper (base) multilingual model. The ASR output is stored in hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = []\n",
    "for sample in data[\"file\"]:\n",
    "    hypotheses.append((model.transcribe(sample, language=\"Spanish\"))['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the output transcriptions to the data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hypothesis\"]=hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 5 output transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Su álgase dio con el cambio de sitio.',\n",
       " ' Es un originario de lo este África Tropical y de Borneo.',\n",
       " ' Actualmente, milita en el club Oriente Petrolero de la Primera División de Bolivia.',\n",
       " ' La voz es de gran belleza y amplia.',\n",
       " ' Tienen notables colecciones arqueológicas y etnográficas.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hypothesis\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcription hypotheses, references and translations are normalized using the Whisper basic text standardisation/normalization module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "data[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\n",
    "data[\"sentence_clean\"] = [normalizer(text) for text in data[\"sentence\"]]\n",
    "data[\"translation_clean\"] = [normalizer(text) for text in data[\"translation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the transcription WER using [JIWER](https://openai.com/index/whisper/) which is a simple and fast python package to evaluate ASR performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 22.04 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wer = jiwer.wer(list(data[\"sentence_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypotheses and translations are stored into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>sentence</th>\n",
       "      <th>translation</th>\n",
       "      <th>transcription_clean</th>\n",
       "      <th>sentence_clean</th>\n",
       "      <th>translation_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Su álgase dio con el cambio de sitio.</td>\n",
       "      <td>Su auge se dio con el cambio de siglo.</td>\n",
       "      <td>Its boom came with the turn of the century.</td>\n",
       "      <td>su álgase dio con el cambio de sitio</td>\n",
       "      <td>su auge se dio con el cambio de siglo</td>\n",
       "      <td>its boom came with the turn of the century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            transcription  \\\n",
       "0   Su álgase dio con el cambio de sitio.   \n",
       "\n",
       "                                 sentence  \\\n",
       "0  Su auge se dio con el cambio de siglo.   \n",
       "\n",
       "                                   translation  \\\n",
       "0  Its boom came with the turn of the century.   \n",
       "\n",
       "                      transcription_clean  \\\n",
       "0   su álgase dio con el cambio de sitio    \n",
       "\n",
       "                           sentence_clean  \\\n",
       "0  su auge se dio con el cambio de siglo    \n",
       "\n",
       "                             translation_clean  \n",
       "0  its boom came with the turn of the century   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(dict(transcription=data[\"hypothesis\"], sentence=data[\"sentence\"], translation=data[\"translation\"], transcription_clean=data[\"hypothesis_clean\"],  sentence_clean=data[\"sentence_clean\"], translation_clean=data[\"translation_clean\"] ))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "dataframe.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data is stored into a file using 'csv' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('L4.1_ASR_Whisper_Baseline_dev_Covost2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a similar experiment using a different Covost2 source-english setup. Evaluate the performance of different whisper models "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
