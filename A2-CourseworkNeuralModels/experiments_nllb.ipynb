{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f539d5b",
   "metadata": {},
   "source": [
    "# A2 Coursework Neural Models\n",
    "## NLLB models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7539bde",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7567c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alumno.upv.es/gdipal1/envs/ta-project/lib/python3.10/site-packages/torchmetrics/utilities/imports.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fbf5562a974241ac370c08618691a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.6.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/alumno.upv.es/gdipal1/envs/ta-project/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:197: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8334e2603f9d4e92a19c6f982265e32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1c348422ce4405bff937bb30fabeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments \n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import IA3Config\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "login(token=\"\")\n",
    "\n",
    "bleu_metric = load(\"sacrebleu\")\n",
    "comet_metric = load(\"comet\")\n",
    "rouge_metric = load(\"rouge\")\n",
    "chrf_metric = load(\"chrf\")\n",
    "\n",
    "DEBUG_MODE = False\n",
    "DEBUG_FRACTION = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4eb0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "opus_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-fr\")\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    opus_dataset = DatasetDict({\n",
    "        split: opus_dataset[split]\n",
    "            .shuffle(seed=42)\n",
    "            .select(range(int(len(opus_dataset[split]) * DEBUG_FRACTION)))\n",
    "        for split in opus_dataset.keys()\n",
    "    })\n",
    "\n",
    "print(opus_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ca45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tok_length = 16\n",
    "src_code_nllb = \"eng_Latn\"\n",
    "tgt_code_nllb = \"fra_Latn\"\n",
    "\n",
    "src_code_mbart = \"en_XX\"\n",
    "tgt_code_mbart = \"fr_XX\"\n",
    "\n",
    "checkpoint_nllb = \"facebook/nllb-200-distilled-600M\"\n",
    "checkpoint_mbart = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "\n",
    "tokenizer_nllb = AutoTokenizer.from_pretrained(\n",
    "    checkpoint_nllb, \n",
    "    padding=True, \n",
    "    pad_to_multiple_of=8, \n",
    "    src_lang=src_code_nllb, \n",
    "    tgt_lang=tgt_code_nllb, \n",
    "    truncation=True, \n",
    "    max_length=max_tok_length,\n",
    ")\n",
    "\n",
    "tokenizer_mbart = AutoTokenizer.from_pretrained(\n",
    "    checkpoint_mbart,\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=8,\n",
    "    src_lang=src_code_mbart,\n",
    "    tgt_lang=tgt_code_mbart,\n",
    "    truncation=True,\n",
    "    max_length=max_tok_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5203176",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = \"en\"\n",
    "target_lang = \"fr\"\n",
    "\n",
    "def preprocess_function_opus(batch, tokenizer):\n",
    "    source_texts = [t[source_lang] for t in batch[\"translation\"]]\n",
    "    target_texts = [t[target_lang] for t in batch[\"translation\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        source_texts,\n",
    "        text_target=target_texts,\n",
    "        truncation=True,\n",
    "        max_length=max_tok_length\n",
    "    )\n",
    "    \n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets_nllb = opus_dataset.map(\n",
    "    lambda batch: preprocess_function_opus(batch, tokenizer_nllb),\n",
    "    batched=True, \n",
    "    num_proc=8\n",
    ")\n",
    "\n",
    "tokenized_datasets_nllb = tokenized_datasets_nllb.filter(\n",
    "    lambda x: len(x[\"input_ids\"]) <= max_tok_length and len(x[\"labels\"]) <= max_tok_length,\n",
    "    desc=f\"Discarding source and target sentences with more than {max_tok_length} tokens\", num_proc=8\n",
    ")\n",
    "\n",
    "tokenized_datasets_mbart = opus_dataset.map(\n",
    "    lambda batch: preprocess_function_opus(batch, tokenizer_mbart),\n",
    "    batched=True, \n",
    "    num_proc=8\n",
    ")\n",
    "\n",
    "tokenized_datasets_mbart = tokenized_datasets_mbart.filter(\n",
    "    lambda x: len(x[\"input_ids\"]) <= max_tok_length and len(x[\"labels\"]) <= max_tok_length,\n",
    "    desc=f\"Discarding source and target sentences with more than {max_tok_length} tokens\", num_proc=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_length_distribution(tokenized_datasets):\n",
    "    dic = {}\n",
    "    for sample in tokenized_datasets['train']:\n",
    "        sample_length = len(sample['input_ids'])\n",
    "        if sample_length not in dic:\n",
    "            dic[sample_length] = 1\n",
    "        else:\n",
    "            dic[sample_length] += 1 \n",
    "\n",
    "    for i in range(1,max_tok_length+1):\n",
    "        if i in dic:\n",
    "            print(f\"{i:>2} {dic[i]:>3}\")\n",
    "            \n",
    "show_length_distribution(tokenized_datasets_nllb)\n",
    "show_length_distribution(tokenized_datasets_mbart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seq2seq_model(\n",
    "    checkpoint,\n",
    "    quantization_config,\n",
    "    tokenizer = None,\n",
    "    peft_config = None,\n",
    "    train_mode = False\n",
    "):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        checkpoint,\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "    model = prepare_model_for_kbit_training(\n",
    "        model,\n",
    "        use_gradient_checkpointing=False,\n",
    "        gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    "    )\n",
    "\n",
    "    if not train_mode:\n",
    "        return model\n",
    "\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "    collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        pad_to_multiple_of=8\n",
    "    )\n",
    "\n",
    "    return model, collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoraConfig_nllb = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "LoraConfig_mbart = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "IA3Config_mbart = IA3Config(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc1\", \"fc2\"],\n",
    "    feedforward_modules=[\"fc1\", \"fc2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "    \n",
    "def setup_training_args(model_name, lr = None, extra = None):\n",
    "    output_save_dir = model_name\n",
    "    if not lr is None:\n",
    "        output_save_dir += f\"-lr{lr}\"\n",
    "    if not extra is None:\n",
    "        output_save_dir += f\"-{extra}\"\n",
    "        \n",
    "    return Seq2SeqTrainingArguments(\n",
    "        output_dir=output_save_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        num_train_epochs=2,\n",
    "        predict_with_generate=True,\n",
    "        logging_strategy=\"epoch\",\n",
    "        disable_tqdm=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6747c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    \n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds, tokenizer, training = False):\n",
    "    if training:\n",
    "        preds, labels = eval_preds\n",
    "    else:\n",
    "        inputs, preds, labels = eval_preds\n",
    "\n",
    "    if not training and not isinstance(inputs, list):\n",
    "        inputs = list(inputs)\n",
    "    if not isinstance(labels, list):\n",
    "        labels = list(labels)\n",
    "        \n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace negative ids in labels as we can't decode them.\n",
    "    if not training:    \n",
    "        inputs = [\n",
    "            [tokenizer.pad_token_id if j < 0 else j for j in input]\n",
    "            for input in inputs\n",
    "        ]\n",
    "        decoded_inputs = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "\n",
    "    labels = [\n",
    "        [tokenizer.pad_token_id if j < 0 else j for j in label]\n",
    "        for label in labels\n",
    "    ]\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    #BLEU\n",
    "    bleu_result = bleu_metric.compute(predictions=decoded_preds, references=[decoded_labels[i] for i in range(len(decoded_labels))])\n",
    "    result = {\"bleu\": bleu_result[\"score\"]}\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result[\"rougeL\"] = rouge_result[\"rougeL\"]\n",
    "\n",
    "    # chrF\n",
    "    chrf_result = chrf_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result[\"chrf\"] = chrf_result[\"score\"]\n",
    "    \n",
    "    # COMET\n",
    "    if not training:\n",
    "        comet_result = comet_metric.compute(sources=decoded_inputs, predictions=decoded_preds, references=decoded_labels)\n",
    "        result[\"comet\"] = comet_result[\"mean_score\"] * 100\n",
    "\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trainer(\n",
    "    model,\n",
    "    collator,\n",
    "    tokenizer,\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    training_args,\n",
    "):\n",
    "    return Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=lambda eval_preds: compute_metrics(\n",
    "            eval_preds, tokenizer, training=True\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486261b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_baseline_nllb = build_seq2seq_model(\n",
    "#     checkpoint_nllb,\n",
    "#     quantization_config,\n",
    "#     train_mode=False\n",
    "# )\n",
    "\n",
    "# # LR = 5e-5\n",
    "# model_nllb_lr5e5, collator_nllb_lr5e5 = build_seq2seq_model(\n",
    "#     checkpoint_nllb,\n",
    "#     quantization_config,\n",
    "#     tokenizer_nllb,\n",
    "#     LoraConfig_nllb,\n",
    "#     train_mode=True\n",
    "# )\n",
    "\n",
    "# trainer_nllb_lr5e5 = build_trainer(\n",
    "#     model_nllb_lr5e5,\n",
    "#     collator_nllb_lr5e5,\n",
    "#     tokenizer_nllb,\n",
    "#     tokenized_datasets_nllb[\"train\"],\n",
    "#     tokenized_datasets_nllb[\"validation\"],\n",
    "#     setup_training_args(\"nllb\", lr = 5e-5)\n",
    "# )\n",
    "\n",
    "# trainer_nllb_lr5e5.train()\n",
    "\n",
    "\n",
    "# # LR = 1e-4\n",
    "# model_nllb_lr1e4, collator_nllb_lr1e4 = build_seq2seq_model(\n",
    "#     checkpoint_nllb,\n",
    "#     quantization_config,\n",
    "#     tokenizer_nllb,\n",
    "#     LoraConfig_nllb,\n",
    "#     train_mode=True\n",
    "# )\n",
    "\n",
    "# trainer_nllb_lr1e4 = build_trainer(\n",
    "#     model_nllb_lr1e4,\n",
    "#     collator_nllb_lr1e4,\n",
    "#     tokenizer_nllb,\n",
    "#     tokenized_datasets_nllb[\"train\"],\n",
    "#     tokenized_datasets_nllb[\"validation\"],\n",
    "#     setup_training_args(\"nllb\", lr = 1e-4)\n",
    "# )\n",
    "\n",
    "# trainer_nllb_lr1e4.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eaafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_baseline_mbart = build_seq2seq_model(\n",
    "    checkpoint_mbart,\n",
    "    quantization_config,\n",
    "    train_mode=False\n",
    ")\n",
    "\n",
    "model_finetuned_mbart_lora, collator_mbart = build_seq2seq_model(\n",
    "    checkpoint_mbart,\n",
    "    quantization_config,\n",
    "    tokenizer_mbart,\n",
    "    LoraConfig_mbart,\n",
    "    train_mode=True\n",
    ")\n",
    "\n",
    "trainer_mbart_lora = build_trainer(\n",
    "    model_finetuned_mbart_lora,\n",
    "    collator_mbart,\n",
    "    tokenizer_mbart,\n",
    "    tokenized_datasets_mbart[\"train\"],\n",
    "    tokenized_datasets_mbart[\"validation\"],\n",
    "    setup_training_args(\"mbart\", lr = 1e-4, extra=\"lora\")\n",
    ")\n",
    "\n",
    "trainer_mbart_lora.train()\n",
    "\n",
    "model_finetuned_mbart_ia3, collator_mbart = build_seq2seq_model(\n",
    "    checkpoint_mbart,\n",
    "    quantization_config,\n",
    "    tokenizer_mbart,\n",
    "    IA3Config_mbart,\n",
    "    train_mode=True\n",
    ")\n",
    "\n",
    "trainer_mbart_ia3 = build_trainer(\n",
    "    model_finetuned_mbart_ia3,\n",
    "    collator_mbart,\n",
    "    tokenizer_mbart,\n",
    "    tokenized_datasets_mbart[\"train\"],\n",
    "    tokenized_datasets_mbart[\"validation\"],\n",
    "    setup_training_args(\"mbart\", lr = 1e-4, extra=\"ia3\")\n",
    ")\n",
    "\n",
    "trainer_mbart_ia3.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518d3ba",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config_nllb = GenerationConfig.from_pretrained(\n",
    "    checkpoint_nllb,\n",
    ")\n",
    "\n",
    "generation_config_mbart = GenerationConfig.from_pretrained(\n",
    "    checkpoint_mbart,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0eb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokenized_test_nllb = tokenized_datasets_nllb['test'].batch(batch_size)\n",
    "batch_tokenized_test_mbart = tokenized_datasets_mbart['test'].batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb74220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, batch_tokenized_test, tokenizer, generation_config, n_beams=1):\n",
    "    number_of_batches = len(batch_tokenized_test[\"translation\"])\n",
    "    input_sequences = []\n",
    "    preds_sequences = []\n",
    "    labels_sequences = []\n",
    "    for i in range(number_of_batches):\n",
    "        batch_tokenized_test_src = list(batch_tokenized_test[\"translation\"][i][j][source_lang] for j in range(len(batch_tokenized_test[\"translation\"][i])))\n",
    "        batch_tokenized_test_tgt = list(batch_tokenized_test[\"translation\"][i][j][target_lang] for j in range(len(batch_tokenized_test[\"translation\"][i])))\n",
    "        inputs = tokenizer(\n",
    "            batch_tokenized_test_src, \n",
    "            max_length=max_tok_length, \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True,\n",
    "            )\n",
    "        labels = tokenizer(\n",
    "            batch_tokenized_test_tgt, \n",
    "            max_length=max_tok_length, \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True,\n",
    "        )\n",
    "        with torch.no_grad():    \n",
    "            \n",
    "            bos_id = None\n",
    "            \n",
    "            if tokenizer == tokenizer_nllb:\n",
    "                bos_id = tokenizer.convert_tokens_to_ids(tgt_code_nllb)\n",
    "            else:\n",
    "                bos_id = tokenizer.lang_code_to_id[tgt_code_mbart]\n",
    "            \n",
    "            output_batch = model.generate(\n",
    "                generation_config=generation_config, \n",
    "                input_ids=inputs[\"input_ids\"].cuda(), \n",
    "                attention_mask=inputs[\"attention_mask\"].cuda(), \n",
    "                forced_bos_token_id=bos_id, \n",
    "                max_length = max_tok_length, \n",
    "                num_beams=n_beams, \n",
    "                do_sample=False,\n",
    "                )\n",
    "        input_sequences.extend(inputs[\"input_ids\"].cpu())\n",
    "        preds_sequences.extend(output_batch.cpu())\n",
    "        labels_sequences.extend(labels[\"input_ids\"].cpu())\n",
    "    return input_sequences, preds_sequences, labels_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5311e",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definiamo le configurazioni da testare\n",
    "eval_configs = [\n",
    "    # {\"model\": model_baseline_nllb,          \"tokenizer\": tokenizer_nllb, \"name\": \"NLLB\", \"finetuned\": False, \"lr\": None, \"num_beams\": 1},\n",
    "    # {\"model\": model_nllb_lr5e5,             \"tokenizer\": tokenizer_nllb, \"name\": \"NLLB\", \"finetuned\": True,  \"lr\": 5e-5, \"num_beams\": 1},\n",
    "    # {\"model\": model_nllb_lr1e4,             \"tokenizer\": tokenizer_nllb, \"name\": \"NLLB\", \"finetuned\": True,  \"lr\": 1e-4, \"num_beams\": 1},\n",
    "    # {\"model\": model_baseline_nllb,          \"tokenizer\": tokenizer_nllb, \"name\": \"NLLB\", \"finetuned\": False, \"lr\": None, \"num_beams\": 4},\n",
    "    # {\"model\": model_nllb_lr5e5,             \"tokenizer\": tokenizer_nllb, \"name\": \"NLLB\", \"finetuned\": True,  \"lr\": 5e-5, \"num_beams\": 4},\n",
    "    # {\"model\": model_nllb_lr1e4,             \"tokenizer\": tokenizer_nllb, \"name\": \"NLLB\", \"finetuned\": True,  \"lr\": 1e-4, \"num_beams\": 4},\n",
    "    {\"model\": model_baseline_mbart,         \"tokenizer\": tokenizer_mbart,\"name\": \"MBART\",\"finetuned\": False, \"peft\": \"Lora\", \"num_beams\": 1},\n",
    "    {\"model\": model_finetuned_mbart_lora,   \"tokenizer\": tokenizer_mbart,\"name\": \"MBART\",\"finetuned\": True,  \"peft\": \"Lora\", \"num_beams\": 1},\n",
    "    {\"model\": model_finetuned_mbart_ia3, \"tokenizer\": tokenizer_mbart,\"name\": \"MBART\",\"finetuned\": True,  \"peft\": \"IA3\", \"num_beams\": 1},\n",
    "    {\"model\": model_baseline_mbart,         \"tokenizer\": tokenizer_mbart,\"name\": \"MBART\",\"finetuned\": False, \"peft\": \"Lora\", \"num_beams\": 4},\n",
    "    {\"model\": model_finetuned_mbart_lora,   \"tokenizer\": tokenizer_mbart,\"name\": \"MBART\",\"finetuned\": True,  \"peft\": \"Lora\", \"num_beams\": 4},\n",
    "    {\"model\": model_finetuned_mbart_ia3, \"tokenizer\": tokenizer_mbart,\"name\": \"MBART\",\"finetuned\": True,  \"peft\": \"IA3\", \"num_beams\": 4},\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for cfg in eval_configs:\n",
    "    model = cfg[\"model\"]\n",
    "    tokenizer = cfg[\"tokenizer\"]\n",
    "    name = cfg[\"name\"]\n",
    "    finetuned = cfg[\"finetuned\"]\n",
    "    lr = cfg.get(\"lr\", None)\n",
    "    peft = cfg.get(\"peft\", None)\n",
    "    num_beams = cfg[\"num_beams\"]\n",
    "\n",
    "    batch_tokenized_test = batch_tokenized_test_nllb if name == \"NLLB\" else batch_tokenized_test_mbart\n",
    "\n",
    "    input_seqs, pred_seqs, label_seqs = evaluate_model(\n",
    "        model, batch_tokenized_test, tokenizer, \n",
    "        generation_config_nllb if name==\"NLLB\" else generation_config_mbart,\n",
    "        n_beams=num_beams\n",
    "    )\n",
    "\n",
    "    metrics = compute_metrics((input_seqs, pred_seqs, label_seqs), tokenizer)\n",
    "\n",
    "    result = {\n",
    "        \"Model\": name,\n",
    "        \"Finetuned\": finetuned,\n",
    "        \"Decoding\": \"Greedy\" if num_beams==1 else f\"Beam {num_beams}\",\n",
    "        \"BLEU\": metrics[\"bleu\"],\n",
    "        \"COMET\": metrics[\"comet\"],\n",
    "        \"ROUGE-L\": metrics[\"rougeL\"],\n",
    "        \"chrF\": metrics[\"chrf\"],\n",
    "    }\n",
    "\n",
    "    if lr is not None:\n",
    "        result[\"LR\"] = lr\n",
    "    if peft is not None:\n",
    "        result[\"PEFT\"] = peft\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "cols_order = [\"Model\", \"Finetuned\", \"LR\", \"PEFT\", \"Decoding\", \"BLEU\", \"COMET\", \"ROUGE-L\", \"chrF\"]\n",
    "df_results = df_results.reindex(columns=[c for c in cols_order if c in df_results.columns])\n",
    "\n",
    "\n",
    "df_results[\"ΔBLEU\"] = df_results.groupby([\"Model\", \"Decoding\"])[\"BLEU\"].transform(lambda x: x - x.iloc[0])\n",
    "df_results[\"ΔROUGE-L\"] = df_results.groupby([\"Model\", \"Decoding\"])[\"ROUGE-L\"].transform(lambda x: x - x.iloc[0])\n",
    "df_results[\"ΔchrF\"] = df_results.groupby([\"Model\", \"Decoding\"])[\"chrF\"].transform(lambda x: x - x.iloc[0])\n",
    "df_results[\"ΔCOMET\"] = df_results.groupby([\"Model\", \"Decoding\"])[\"COMET\"].transform(lambda x: x - x.iloc[0])\n",
    "\n",
    "df_results = df_results.sort_values(by=[\"Model\", \"Decoding\", \"Finetuned\"], ascending=[True, True, False])\n",
    "\n",
    "df_nllb = df_results[df_results[\"Model\"]==\"NLLB\"].copy()\n",
    "df_mbart = df_results[df_results[\"Model\"]==\"MBART\"].copy()\n",
    "\n",
    "# print(df_nllb.to_string(index=False))\n",
    "# df_nllb.to_csv(\"results_nllb.csv\", index=False)\n",
    "\n",
    "print(df_mbart.to_string(index=False))\n",
    "df_mbart.to_csv(\"results_mbart.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
